{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "78CZvtsRgV-B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "78CZvtsRgV-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "0SCyquingbDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U earthengine-api --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbc5ma9bvOSu",
        "outputId": "4fc761a2-7397-4c23-ee7c-93ada96fba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.8/dist-packages (0.1.341)\n",
            "Collecting earthengine-api\n",
            "  Downloading earthengine-api-0.1.342.tar.gz (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.6/245.6 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: earthengine-api\n",
            "  Building wheel for earthengine-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for earthengine-api: filename=earthengine_api-0.1.342-py3-none-any.whl size=275071 sha256=248bf64cf03341650ada8c6e792302bab806ca827d5a89f9afadaa550b1086a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/40/09/65ab71456d17235b2d83b3a3d2198b7209fce966722cfb7482\n",
            "Successfully built earthengine-api\n",
            "Installing collected packages: earthengine-api\n",
            "  Attempting uninstall: earthengine-api\n",
            "    Found existing installation: earthengine-api 0.1.341\n",
            "    Uninstalling earthengine-api-0.1.341:\n",
            "      Successfully uninstalled earthengine-api-0.1.341\n",
            "Successfully installed earthengine-api-0.1.342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnLcozABvOU0",
        "outputId": "2fd5378c-be23-4c31-8e01-dcb408888ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=y8YxYAdA0cH-BQ5ROqhGlF6d6AHKqGMcn-0YUN2USJQ&tc=4mg-lblTrygIgN3yNwbERWG7u2Ww2zNenM-p_iVaFXg&cc=I45mY560Qk9EybmEtONcCgr3YLvj04Kk-rowS_EW5fg\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AWtgzh7kgG4Qtsc9m8hWPq0KUzT0hrObj_seiMFsiFjn38w7_wlD3kEBsSo\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF7pblqUvOXa",
        "outputId": "b3102f79-579a-43e8-c1c8-f05e53a68a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "print(folium.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ekusMjvOZ4",
        "outputId": "d51fe0dd-b433-4136-bd87-9e73f4cd6219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UqXjoduPeWZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Define* variables"
      ],
      "metadata": {
        "id": "yKC7PSCrwO-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE WITH YOUR CLOUD PROJECT!\n",
        "PROJECT = 'ee_challenge'\n",
        "\n",
        "# Cloud Storage bucket with training and testing datasets.\n",
        "DATA_BUCKET = 'ee-docs-demos'\n",
        "# Output bucket for trained models.  You must be able to write into this bucket.\n",
        "OUTPUT_BUCKET = 'ee_challenge_bucket'\n",
        "\n",
        "# This is a good region for hosting AI models.\n",
        "REGION = 'us-central1'\n",
        "\n",
        "# Training and testing dataset file names in the Cloud Storage bucket.\n",
        "TRAIN_FILE_PREFIX = 'Training_demo'\n",
        "TEST_FILE_PREFIX = 'Testing_demo'\n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + DATA_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH = 'gs://' + DATA_BUCKET + '/' + TEST_FILE_PREFIX + file_extension\n",
        "\n",
        "# The labels, consecutive integer indices starting from zero, are stored in\n",
        "# this property, set on each point.\n",
        "LABEL = 'landcover'\n",
        "# Number of label values, i.e. number of classes in the classification.\n",
        "N_CLASSES = 3\n",
        "\n",
        "# Use Landsat 8 surface reflectance data for predictors.\n",
        "L8SR = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
        "# Use these bands for prediction.\n",
        "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "# These names are used to specify properties in the export of \n",
        "# training/testing data and to define the mapping between names and data\n",
        "# when reading into TensorFlow datasets.\n",
        "FEATURE_NAMES = list(BANDS)\n",
        "FEATURE_NAMES.append(LABEL)\n",
        "\n",
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
        "]\n",
        "\n",
        "# Dictionary with feature names as keys, fixed-length features as values.\n",
        "FEATURES_DICT = dict(zip(FEATURE_NAMES, columns))"
      ],
      "metadata": {
        "id": "_n1FLOp3vOcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O4rbYj9hvOeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in Data"
      ],
      "metadata": {
        "id": "5Csi9rz5gj1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check  permission\n",
        "print('Found training file.' if tf.io.gfile.exists(TRAIN_FILE_PATH) \n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.io.gfile.exists(TEST_FILE_PATH) \n",
        "    else 'No testing file found.')"
      ],
      "metadata": {
        "id": "9WZZJWoBgnec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "train_dataset = tf.data.TFRecordDataset([TRAIN_FILE_PATH, TEST_FILE_PATH],\n",
        "                                        compression_type='GZIP')\n",
        "\n",
        "# Print the first record to check.\n",
        "print(iter(train_dataset).next())"
      ],
      "metadata": {
        "id": "5tzz73Y1gqTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse Dataset\n",
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the LABEL, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=4)\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "pprint(iter(parsed_dataset).next())"
      ],
      "metadata": {
        "id": "W6c1Swofgshh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust dimension and shape\n",
        "# Inputs as a tuple.  Make predictors 1x1xP and labels 1x1xN_CLASSES.\n",
        "def to_tuple(inputs, label):\n",
        "  return (tf.expand_dims(tf.transpose(list(inputs.values())), 1),\n",
        "          tf.expand_dims(tf.one_hot(indices=label, depth=N_CLASSES), 1))\n",
        "\n",
        "input_dataset = parsed_dataset.map(to_tuple)\n",
        "# Check the first one.\n",
        "pprint(iter(input_dataset).next())\n",
        "\n",
        "input_dataset = input_dataset.shuffle(128).batch(8)"
      ],
      "metadata": {
        "id": "YoY3hbd7gwyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models with Kernals"
      ],
      "metadata": {
        "id": "l3fe1OyIxbO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Define the layers in the model.  Note the 1x1 kernels.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input((None, None, len(BANDS),)),\n",
        "  tf.keras.layers.Conv2D(64, (1,1), activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Conv2D(N_CLASSES, (1,1), activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "\"\"\"\n",
        "# RNN model for longe term memory\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=1000, output_dim=64),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "# CNN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (1, 1), activation='relu', input_shape=(X, X, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Compile the model with the specified loss and optimizer functions.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to the training data.  Lucky number 7.\n",
        "model.fit(x=input_dataset, epochs=7)"
      ],
      "metadata": {
        "id": "1bblFtE8xcca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "fau9DwRhyYs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/demo_pixel_model'\n",
        "model.save(MODEL_DIR, save_format='tf')"
      ],
      "metadata": {
        "id": "Wyt9pnEDyY0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EEification"
      ],
      "metadata": {
        "id": "2kYCmOKEhBKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(MODEL_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"output\"}) + \"'\"\n",
        "print(input_dict)\n",
        "print(output_dict)"
      ],
      "metadata": {
        "id": "a8JzKzmghL6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://' + OUTPUT_BUCKET + '/eeified_pixel_model'\n",
        "\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {MODEL_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "metadata": {
        "id": "rVexXhKchNUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Delpoy the  model on AI Platform\n",
        "\n",
        "\"\"\"\n",
        "Now there is another TensorFlow SavedModel stored in EEIFIED_DIR ready for hosting by AI Platform. Do that from the gcloud command line tool, installed in the Colab runtime by default. Be sure to specify a regional model with the REGION parameter. Note that the MODEL_NAME must be unique. If you already have a model by that name, either name a new model or a new version of the old model. The Cloud Console AI Platform models page is useful for monitoring your models.\n",
        "\n",
        "If you change anything about the trained model, you'll need to re-EEify it and create a new version!\n",
        "\n",
        "\"\"\"\n",
        "MODEL_NAME = 'pixel_demo_model'\n",
        "VERSION_NAME = 'v0'\n",
        "\n",
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION}\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --runtime-version=2.3 \\\n",
        "  --python-version=3.7\n"
      ],
      "metadata": {
        "id": "873x_e5UhUsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNJNLzWahgQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the hosted model from Earth Engine"
      ],
      "metadata": {
        "id": "aC4PAYvJhtbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloud masking function.\n",
        "def maskL8sr(image):\n",
        "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "  qa = image.select('pixel_qa')\n",
        "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  return image.updateMask(mask).select(BANDS).divide(10000)\n",
        "\n",
        "# The image input data is a 2018 cloud-masked median composite.\n",
        "image = L8SR.filterDate('2018-01-01', '2018-12-31').map(maskL8sr).median()\n",
        "\n",
        "# Get a map ID for display in folium.\n",
        "rgb_vis = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3, 'format': 'png'}\n",
        "mapid = image.getMapId(rgb_vis)\n",
        "\n",
        "# Turn into an array image for input to the model.\n",
        "array_image = image.float().toArray()\n",
        "\n",
        "# Point to the model hosted on AI Platform.  If you specified a region other\n",
        "# than the default (us-central1) at model creation, specify it here.\n",
        "model = ee.Model.fromAiPlatformPredictor(\n",
        "    projectName=PROJECT,\n",
        "    modelName=MODEL_NAME,\n",
        "    version=VERSION_NAME,\n",
        "    # Can be anything, but don't make it too big.\n",
        "    inputTileSize=[8, 8],\n",
        "    # Keep this the same as your training data.\n",
        "    proj=ee.Projection('EPSG:4326').atScale(30),\n",
        "    fixInputProj=True,\n",
        "    # Note the names here need to match what you specified in the\n",
        "    # output dictionary you passed to the EEifier.\n",
        "    outputBands={'output': {\n",
        "        'type': ee.PixelType.float(),\n",
        "        'dimensions': 1\n",
        "      }\n",
        "    },\n",
        ")\n",
        "\n",
        "# model.predictImage outputs a one dimensional array image that\n",
        "# packs the output nodes of your model into an array.  These\n",
        "# are class probabilities that you need to unpack into a \n",
        "# multiband image with arrayFlatten().  If you want class\n",
        "# labels, use arrayArgmax() as follows.\n",
        "predictions = model.predictImage(array_image)\n",
        "probabilities = predictions.arrayFlatten([['bare', 'veg', 'water']])\n",
        "label = predictions.arrayArgmax().arrayGet([0]).rename('label')\n",
        "\n",
        "# Get map IDs for display in folium.\n",
        "probability_vis = {\n",
        "    'bands': ['bare', 'veg', 'water'], 'max': 0.5, 'format': 'png'\n",
        "}\n",
        "label_vis = {\n",
        "    'palette': ['red', 'green', 'blue'], 'min': 0, 'max': 2, 'format': 'png'\n",
        "}\n",
        "probability_mapid = probabilities.getMapId(probability_vis)\n",
        "label_mapid = label.getMapId(label_vis)\n",
        "\n",
        "# Visualize the input imagery and the predictions.\n",
        "map = folium.Map(location=[37.6413, -122.2582], zoom_start=11)\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=label_mapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='predicted label',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probability_mapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "id": "m7zqUbzQhgS5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}