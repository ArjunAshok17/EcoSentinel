# EcoSentinel #
In this document is the operating instructions for running the EcoSentinel pipeline on your own hardware, unlocking the same insights we have worked hard to develop. We are making this project completely open-source in an effort to stay transparent about our methods of analysis, earning some trust from the public, legislative officials, and company executives around the world about the information we are providing.

Below, we provide a high-level overview of the custom-built pipeline we have constructed, and then dive into the details of each step.

## Pipeline Overview ##
The EcoSentinel pipeline begins with a continuous import of satellite imagery from Google Earth Engine. Using its API, we can deliver fresh landsat images for monitoring ecological damage.

Because Google Earth Engine has its limitations with analyzing the data, we then move into Python for our Tensorflow model, analyzing segments of the Earth’s landmass for deforestation over time.

The data we gather on forest coverage is then fed into our time-series analysis, where we consider short and long terms trends in ecological damage to best predict how Earth’s ecological systems will grow or shrink in the future.

Those trends are then weighted to take calculate a few key metrics:
* Risk, the risk of an ecosystem going beyond the point of recovery
* Grades, an evaluation of countries (and eventually companies) on their effectiveness in reigning in ecological destruction
* And in the future, a predictive system that can project the effectiveness of any legislation or other efforts based on past trends

All of these findings will then be presented in digestible, yet informative, visualizations on our website.

To read a graphic with the pipeline, check out the `EcoSentinel_Pipeline.docx` file.

To read a more in-depth overview of EcoSentinel, including the problems we are targeting and how our implementation works, read the `PROJECTOVERVIEW.md` file. It contains our entire project outline that we used to construct the pipeline. Be wary of typos though, it was largely intended as documentation for developers of the project.

# IMPORTANT NOTE #
The following description will sound complicated: that's because it very much is. And our pipeline is far from over. We have designed EcoSentinel to expand from just identifying a problem to flat-out solving it in some respects (read more in our project overview).

What we have laid out here is not a product, but rather a framework from which we can expand on. From targeting other types of ecological loss (e.g. aquatic ecosystems, coastal erosion, etc.) to creating new mediums in which to showcase the pipeline's results (i.e. an app that tells you how "green" a product you take a picture of is), we have big plans for the future.

But to you, our user, there is no point in overcomplicating an entire process in an effort to provide transparency. So as a compromise, we provide our all-inclusive file, `ecosentinel.ipynb`: a notebook that carries you step-by-step through the whole pipeline, allowing you to analyze one country, or a set of countries, at a time. As our pipeline expands, our notebook will expand with it, allowing anyone to do what we do on a smaller scale, locally.

## Earth Engine ##
In the `ee_scripts.js` file, we have uploaded some of the scripts we used to calculate certain metrics, and just generally get accustomed to the interface in Earth Engine. These scripts ended up not being needed, as the bulk of the data import is done in Python, but it's a nice way to understand the data repository we are working with.

In our `label_data.py` file, we have started the development of ways to label our own data using basic computer vision and image manipulation techniques. This will be iterated on to provide a more robust labeling of data, but for now this serves as a last-choice backup for our model training to be conducted.

## Tensorflow Model ##
In the `ee_model.ipynb` files, we have included our whole tensorflow model training in an easy to understand and run notebook.

The `geo_model.py` file includes our first attempt at creating a framework to use, but it serves now as an experimentation file for testing out different weights, etc. Any users of EcoSentinel need not worry about this file, this is simply as a reference for the developers of EcoSentinel.

## Multi-Regressive Analysis ##
In the `multi_regressor.py` file, you can find the main algorithm driving our post-monitoring analysis. Here, we use the data generated by our TensorFlow model to conduct "self-fulfilling" predictions about the rate of deforestation. The results of this algorithm are what powers the risk and grading analysis.

In `risk_analysis.py`, we calculate risk using a custom weighted formula and predictions from the linear model generated in `multi_regressor.py`.

In `grade_analysis.py`, we calculate grades using the risk we measure for a certain country and another custom weighted formula.

## Web App ##
The code for our web app is also published alongside these files. Although we fully expect users to interact with the EcoSentinel pipeline through the user interface of the website, we provide these files as a method of transparency.

Thanks for reading!
- The EcoSentinel Team